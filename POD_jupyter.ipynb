{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e19b5b-0d58-4a9e-8f66-d7a97d51ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras import layers, losses\n",
    "# from tensorflow.keras.models import Model\n",
    "# import keras_tuner as kt\n",
    "# import modred as mr\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from scipy import linalg\n",
    "from sklearn.preprocessing import normalize\n",
    "# from scipy import fftpack\n",
    "from pathlib import Path\n",
    "from scipy.optimize import minimize, differential_evolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b14395f-b08f-4c68-8e52-445b43900127",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.use('Agg')\n",
    "\n",
    "# density_df_400_2013 = pd.read_csv('Data/2013_HASDM_400-475KM.den', delim_whitespace=True,\n",
    "#                                   header=None)\n",
    "# density_np_400_2013 = pd.DataFrame.to_numpy(density_df_400_2013)\n",
    "# del density_df_400_2013\n",
    "# If you want to add more altitudes (increase the initial dimension of the problem), uncomment the followings:\n",
    "density_df_500_2013 = pd.read_csv('Data/2013_HASDM_500-575KM.den', delim_whitespace=True,\n",
    "                                  header=None)\n",
    "density_np_500_2013 = pd.DataFrame.to_numpy(density_df_500_2013)\n",
    "del density_df_500_2013\n",
    "\n",
    "# If you want to add more data (increase the time instants), uncomment the followings:\n",
    "# density_df_400_2014 = pd.read_csv('Data/2014_HASDM_400-475KM.den', delim_whitespace=True,\n",
    "#                                   header=None)\n",
    "# density_np_400_2014 = pd.DataFrame.to_numpy(density_df_400_2014)\n",
    "# del density_df_400_2014\n",
    "\n",
    "nt = 19\n",
    "nphi = 24\n",
    "\n",
    "t = np.linspace(-np.pi / 2, np.pi / 2, nt)\n",
    "phi = np.linspace(0, np.deg2rad(345), nphi)\n",
    "\n",
    "# max_rho1 = np.max(density_np_400_2013[:, 10])\n",
    "# max_rho2 = np.max(density_np_400_2014[:, 10])\n",
    "# max_rho = np.max(np.array([max_rho1, max_rho2]))\n",
    "# density_np_400_2013[:, 10] = density_np_400_2013[:, 10] / max_rho\n",
    "# density_np_400_2014[:, 10] = density_np_400_2014[:, 10] / max_rho\n",
    "\n",
    "# max_rho = np.max(density_np_400_2013[:, 10])\n",
    "max_rho = np.max(density_np_500_2013[:, 10])\n",
    "# max_rho = np.max(np.array([max_rho2, max_rho]))\n",
    "\n",
    "# density_np_400_2013[:, 10] = density_np_400_2013[:, 10] / max_rho\n",
    "density_np_500_2013[:, 10] = density_np_500_2013[:, 10] / max_rho\n",
    "# density_np_400_2014[:, 10] = density_np_400_2014[:, 10] / max_rho\n",
    "\n",
    "rho_list = []\n",
    "rho_list1 = []\n",
    "rho_list2 = []\n",
    "\n",
    "for i in range(int(1331520 / (nt * nphi))):  # 1335168\n",
    "    # rho_400_i_2013 = density_np_400_2013[i * (4 * nt * nphi):(i + 1) * (4 * nt * nphi), 10]\n",
    "    # rho_polar_400_i_2013 = np.reshape(rho_400_i_2013, (nt, nphi, 4))\n",
    "\n",
    "    # rho_400_i_2014 = density_np_400_2014[i * (4 * nt * nphi):(i + 1) * (4 * nt * nphi), 10]\n",
    "    # rho_polar_400_i_2014 = np.reshape(rho_400_i_2014, (nt, nphi, 4))\n",
    "\n",
    "    rho_500_i = density_np_500_2013[i * (4 * nt * nphi):(i + 1) * (4 * nt * nphi), 10]\n",
    "    rho_polar_500_i_2013 = np.reshape(rho_500_i, (nt, nphi, 4))\n",
    "    #\n",
    "    # rho_polar = np.concatenate(\n",
    "    #     (rho_polar_400_i_2013, rho_polar_400_i_2014), axis=2)\n",
    "\n",
    "    # rho_polar_2013 = rho_polar_400_i_2013\n",
    "    # rho_polar_2013 = np.concatenate(\n",
    "    #     (rho_polar_400_i_2013, rho_polar_500_i_2013), axis=2)\n",
    "\n",
    "    # rho_polar_2014 = rho_polar_400_i_2014\n",
    "\n",
    "    # rho_list1.append(rho_polar_400_i_2013)\n",
    "    # rho_list2.append(rho_polar_400_i_2014)\n",
    "    rho_list1.append(rho_polar_500_i_2013)\n",
    "\n",
    "\n",
    "\n",
    "# rho1 = np.array(rho_list1)\n",
    "# rho2 = np.array(rho_list2)\n",
    "# rho = np.concatenate((rho1, rho2), axis=0)  # Shape: (5840, 19, 24, 4)\n",
    "\n",
    "rho = np.array(rho_list1)\n",
    "\n",
    "rho_zeros = np.zeros((2920, 20, 24, 4))  # 2920, 20, 24, 4 \n",
    "rho_zeros[:, :nt, :nphi, :] = rho\n",
    "del rho_list1, rho  #, rho_list2, rho1, rho2\n",
    "\n",
    "training_data = rho_zeros[:2000] # 2000\n",
    "validation_data = rho_zeros[2000:]\n",
    "\n",
    "training_data_resh = np.reshape(training_data, newshape=(2000, 20*24*4))\n",
    "nPoints_val = len(rho_zeros) - len(training_data)\n",
    "validation_data_resh = np.reshape(validation_data, newshape=(nPoints_val, 20*24*4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81060678-b79e-416a-9310-32d3acd3d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_kernel(x, y):\n",
    "    x_normalized = normalize(x, copy=True)\n",
    "    if x is y:\n",
    "        y_normalized = x_normalized\n",
    "    else:\n",
    "        y_normalized = normalize(y, copy=True)\n",
    "    kernels = np.dot(x_normalized, y_normalized.T)\n",
    "    return kernels\n",
    "\n",
    "\n",
    "def my_kernel(X, Y):\n",
    "    # The best one so far: np.dot(np.sin(X), np.sin(Y).T). It may be better than the linear one if a nonlinear\n",
    "    # pre-image would exist\n",
    "    return np.dot(np.sin(X), np.sin(Y).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e1f2cb-8caf-4fbf-b748-edea038441f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nPoints_val = 920  # 840 920\n",
    "validation_data_resh = np.reshape(validation_data, newshape=(nPoints_val, 20*24*4))\n",
    "rhoavg = np.mean(validation_data_resh, axis=0)  # Compute mean\n",
    "rho_msub_val = validation_data_resh.T - np.tile(rhoavg, (nPoints_val, 1)).T  # Mean-subtracted data\n",
    "\n",
    "# print(training_data_resh.shape)\n",
    "rhoavg = np.mean(training_data_resh, axis=0)  # Compute mean\n",
    "nPoints = 2000 # 2000\n",
    "rho_msub = training_data_resh.T - np.tile(rhoavg, (nPoints, 1)).T  # Mean-subtracted data\n",
    "num_modes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d892378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lorenz0_tr = pd.read_csv('output/training_data0.txt')\n",
    "lorenz0_vl = pd.read_csv('output/validation_data0.txt')\n",
    "\n",
    "lorenz0_np_tr = pd.DataFrame.to_numpy(lorenz0_tr)\n",
    "lorenz0_np = pd.DataFrame.to_numpy(lorenz0_vl)\n",
    "\n",
    "decoded0_df = pd.read_csv('output/decoded0.txt')\n",
    "decoded0_np = pd.DataFrame.to_numpy(decoded0_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed0fa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255999, 128)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lorenz0_np_tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266e9bc",
   "metadata": {},
   "source": [
    "The most suitable Kernel: \n",
    "\n",
    "$K(X_1, X_2) = e^{(-\\gamma ||X_1 - X_2||^2)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41521e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=8.28907e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=8.28907e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=5.71867e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=5.71867e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=1.09012e-16): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=1.09012e-16): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=5.08181e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=5.08181e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=1.45866e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=1.45866e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=6.72499e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=6.72499e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=5.01419e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=5.01419e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=1.42127e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=1.42127e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=3.21386e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=3.21386e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=1.83447e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=1.83447e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=6.13362e-18): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=6.13362e-18): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=4.82128e-18): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=4.82128e-18): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=6.4474e-18): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=6.4474e-18): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=1.60764e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=1.60764e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=2.14091e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=2.14091e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=9.53098e-18): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=9.53098e-18): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=7.05719e-18): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=7.05719e-18): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=1.92397e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=1.92397e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=1.02077e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=1.02077e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=4.70404e-18): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=4.70404e-18): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=1.32148e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=1.32148e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=1.33462e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n",
      "c:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\venv\\lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:409: LinAlgWarning: Ill-conditioned matrix (rcond=1.33462e-17): result may not be accurate.\n",
      "  self.dual_coef_ = linalg.solve(K, X, sym_pos=True, overwrite_a=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "[array([6.88349557e-03, 1.81877613e-13]), array([3.50119169e-03, 3.71320461e-11]), array([6.87100506e-03, 9.61876726e-10]), array([5.98371471e-03, 1.03876643e-09]), array([5.55973291e-03, 1.28090382e-10])]\n",
      "[0.11958095343710647, 0.3969503780092596, 0.4373236143938803, 0.5275187893659179, 0.2924873450896861]\n"
     ]
    }
   ],
   "source": [
    "def mykpca(x):\n",
    "    try: \n",
    "        kpca_lor = KernelPCA(n_components=3, kernel=\"rbf\", fit_inverse_transform=True, gamma=x[0],\n",
    "                     alpha=x[1])  #  1e-11\n",
    "        X_kpca_lor = kpca_lor.fit_transform(lorenz0_np)\n",
    "        X_back_kpca_lor = kpca_lor.inverse_transform(X_kpca_lor)\n",
    "        error_adv = lorenz0_np-X_back_kpca_lor\n",
    "        error_norm_adv = linalg.norm(error_adv)\n",
    "        return error_norm_adv\n",
    "    except:\n",
    "        return 1e+10\n",
    "gamma_init = np.linspace(0.01,0.6,num=5)\n",
    "alpha_init = np.linspace(1e-9, 1e-5, num=5)\n",
    "res_x = []\n",
    "res_value = []\n",
    "for i in range(5):\n",
    "    x0 = [gamma_init[i], alpha_init[i]] # alpha_init[i]\n",
    "    # bounds = [(0.2, 0.4), (1e-14, 1e-12)]\n",
    "    res = minimize(mykpca, x0, method='Nelder-Mead', tol=1e-14, options={'maxiter':50, 'disp': True})\n",
    "    # res = differential_evolution(mykpca, bounds, maxiter=10, tol=1e-14, disp=True)\n",
    "    res_x.append(res.x)\n",
    "    res_value.append(res.fun)\n",
    "print(res_x)\n",
    "print(res_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e46b109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.13953125e-02, 1.04687500e-09])]\n"
     ]
    }
   ],
   "source": [
    "print(res_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d908834",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lorenz0_np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\POD_jupyter.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/My_folder/Documents/Politecnico%20di%20Milano/My%20thesis/test_auto/HASDM_ROM/POD_jupyter.ipynb#ch0000009?line=0'>1</a>\u001b[0m \u001b[39m# lorenz0_np = lorenz0_np[:1000, :]\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/My_folder/Documents/Politecnico%20di%20Milano/My%20thesis/test_auto/HASDM_ROM/POD_jupyter.ipynb#ch0000009?line=1'>2</a>\u001b[0m \u001b[39m# lorenz0_np_tr = lorenz0_np_tr[:1000, :]\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/My_folder/Documents/Politecnico%20di%20Milano/My%20thesis/test_auto/HASDM_ROM/POD_jupyter.ipynb#ch0000009?line=2'>3</a>\u001b[0m \u001b[39m# decoded0_np = decoded0_np[:1000, :]\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/My_folder/Documents/Politecnico%20di%20Milano/My%20thesis/test_auto/HASDM_ROM/POD_jupyter.ipynb#ch0000009?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mimport\u001b[39;00m linspace\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/My_folder/Documents/Politecnico%20di%20Milano/My%20thesis/test_auto/HASDM_ROM/POD_jupyter.ipynb#ch0000009?line=7'>8</a>\u001b[0m error_auto_lor \u001b[39m=\u001b[39m lorenz0_np \u001b[39m-\u001b[39m decoded0_np\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/My_folder/Documents/Politecnico%20di%20Milano/My%20thesis/test_auto/HASDM_ROM/POD_jupyter.ipynb#ch0000009?line=8'>9</a>\u001b[0m error_norm_auto_lor \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39mnorm(error_auto_lor)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/My_folder/Documents/Politecnico%20di%20Milano/My%20thesis/test_auto/HASDM_ROM/POD_jupyter.ipynb#ch0000009?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39merror_norm_autoencoder_lorenz:\u001b[39m\u001b[39m'\u001b[39m, error_norm_auto_lor)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lorenz0_np' is not defined"
     ]
    }
   ],
   "source": [
    "# lorenz0_np = lorenz0_np[:1000, :]\n",
    "# lorenz0_np_tr = lorenz0_np_tr[:1000, :]\n",
    "# decoded0_np = decoded0_np[:1000, :]\n",
    "\n",
    "error_auto_lor = lorenz0_np - decoded0_np\n",
    "error_norm_auto_lor = linalg.norm(error_auto_lor)\n",
    "print('error_norm_autoencoder_lorenz:', error_norm_auto_lor)\n",
    "# error_auto_lor = lorenz0_np_tr - decoded0_np\n",
    "# error_norm_auto_lor = linalg.norm(error_auto_lor)\n",
    "# print('error_norm_autoencoder_lorenz_tr:', error_norm_auto_lor)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "X_pca_lin_lor = pca.fit_transform(lorenz0_np)\n",
    "X_back_lin_lor = pca.inverse_transform(X_pca_lin_lor)\n",
    "error_adv = lorenz0_np-X_back_lin_lor\n",
    "error_norm_adv = linalg.norm(error_adv)\n",
    "print('error_norm_lorenz:', error_norm_adv)\n",
    "x = [6.88349557e-03, 1.81877613e-13]\n",
    "kpca_lor = KernelPCA(n_components=3, kernel=\"rbf\", fit_inverse_transform=True, gamma=x[0],\n",
    "                     alpha=x[1])  #  0.011, 1e-11\n",
    "X_kpca_lor = kpca_lor.fit_transform(lorenz0_np)\n",
    "X_back_kpca_lor = kpca_lor.inverse_transform(X_kpca_lor)\n",
    "error_adv = lorenz0_np-X_back_kpca_lor\n",
    "error_norm_adv = linalg.norm(error_adv)\n",
    "print('error_norm_lorenz_kpca:', error_norm_adv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8a8aa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asd\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize, differential_evolution\n",
    "def mykpca(x):\n",
    "    try: \n",
    "        kpca = KernelPCA(n_components=10, kernel=\"rbf\", fit_inverse_transform=True, gamma=x[0], alpha=x[1])\n",
    "        X_pca = kpca.fit_transform(rho_msub.T)\n",
    "        X_back = kpca.inverse_transform(X_pca)\n",
    "        X_back = X_back.T\n",
    "        error_adv = rho_msub-X_back\n",
    "        error_norm_adv = linalg.norm(error_adv)\n",
    "        return error_norm_adv\n",
    "    except:\n",
    "        return 1e+10\n",
    "gamma_init = np.linspace(0.1,0.6,num=5)\n",
    "alpha_init = np.linspace(9.52148437e-14, 9.52148437e-9, num=5)\n",
    "res_x = []\n",
    "res_value = []\n",
    "for i in range(5):\n",
    "    x0 = [gamma_init[i], 4.07854175e-14] # alpha_init[i]\n",
    "    # bounds = [(0.2, 0.4), (1e-14, 1e-12)]\n",
    "    res = minimize(mykpca, x0, method='Nelder-Mead', tol=1e-14, options={'maxiter':50, 'disp': True})\n",
    "    # res = differential_evolution(mykpca, bounds, maxiter=10, tol=1e-14, disp=True)\n",
    "    res_x.append(res.x)\n",
    "    res_value.append(res.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8019718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([3.22535513e-01, 5.49440980e-14]), array([3.26689453e-01, 4.66323895e-14]), array([3.27487842e-01, 4.21048114e-14]), array([3.25663757e-01, 4.49891733e-14]), array([3.25336048e-01, 4.91767092e-14])]\n",
      "[0.12991970290535929, 0.1288634639190704, 0.1286555825700649, 0.12868331248343692, 0.12901360063077633]\n"
     ]
    }
   ],
   "source": [
    "print(res_x)\n",
    "print(res_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [array([3.28794335e-01, 4.07854175e-14]), array([1.82838673e-01, 9.81933441e-14])]\n",
    "# [0.1284836616298345, 0.26848314372865445]\n",
    "\n",
    "# x = [3.27369962e-01 4.12452062e-14] # res = minimize(mykpca, x0, method='Nelder-Mead', tol=1e-14, options={'maxiter':100, 'disp': True})\n",
    "\n",
    "# x = [0.31, 7.45058089e-14]\n",
    "# kpca = KernelPCA(n_components=10, kernel=\"rbf\", fit_inverse_transform=True, gamma=x[0], alpha=x[1])\n",
    "# X_pca = kpca.fit_transform(rho_msub.T)\n",
    "# X_back = kpca.inverse_transform(X_pca)\n",
    "# X_back = X_back.T\n",
    "# error_adv = rho_msub-X_back\n",
    "# error_norm_adv = linalg.norm(error_adv)\n",
    "# print(error_norm_adv)\n",
    "\n",
    "# x = [3.27369962e-01, 4.66323895e-14]\n",
    "# x = np.linspace(1e-4, 10, num=10)\n",
    "x = np.arange(-7,2, 0.25)\n",
    "x = 10 ** x\n",
    "# x = np.array([1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 5e-1, 1, 2, 5, 10])\n",
    "kpca_error = np.zeros((1, x.shape[0]))\n",
    "for i in range(x.shape[0]):\n",
    "    kpca1 = KernelPCA(n_components=10, kernel=\"rbf\", fit_inverse_transform=True, gamma=x[i], alpha=4.66323895e-12)\n",
    "    X_pca = kpca1.fit_transform(rho_msub.T)\n",
    "    X_back = kpca1.inverse_transform(X_pca)\n",
    "    X_back = X_back.T\n",
    "    error_adv = rho_msub-X_back\n",
    "    error_norm_adv = linalg.norm(error_adv)\n",
    "    # print(error_norm_adv)\n",
    "    kpca_error[:, i] = error_norm_adv\n",
    "    del kpca1\n",
    "plt.figure()\n",
    "plt.rcParams.update({'font.size': 14})  # increase the font size\n",
    "mpl.rcParams['legend.fontsize'] = 15\n",
    "plt.xlabel(\"Kernel parameter $\\gamma$\")\n",
    "plt.ylabel(\"$L^2$ norm of reconstruction error\")\n",
    "plt.semilogx(x, kpca_error.T, linewidth=2)\n",
    "# plt.plot(kpca_error, linewidth=2) # , label=\"PCA error\"\n",
    "# plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/kpca_vs_gamma.png')\n",
    "\n",
    "# error_adv = np.reshape(error_adv.T, newshape=(2000, 20, 24, 4))\n",
    "# plt.figure()\n",
    "# plt.rcParams.update({'font.size': 14})  # increase the font size\n",
    "# mpl.rcParams['legend.fontsize'] = 15\n",
    "# plt.xlabel(\"Longitude [deg]\")\n",
    "# plt.ylabel(\"Latitude [deg]\")\n",
    "# plt.contourf(np.rad2deg(phi), np.rad2deg(t), np.absolute(error_adv[10, :19, :, 0])/training_data[10, :19, :, 0]*100,\n",
    "#              cmap=\"inferno\", levels=900)\n",
    "# plt.colorbar()\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('output/ReconstructionError_kpca_adv.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a81851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b5bc983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6185030848776232\n",
      "0.41124215511636236\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=num_modes)\n",
    "pca.fit(rho_msub.T)\n",
    "X_pca_lin = pca.fit_transform(rho_msub_val.T)\n",
    "X_back_lin = pca.inverse_transform(X_pca_lin)\n",
    "X_back_lin = X_back_lin.T\n",
    "error_lin = rho_msub_val-X_back_lin\n",
    "error_norm_lin = linalg.norm(error_lin)\n",
    "print(error_norm_lin)\n",
    "x = [0.2575, 4.66323895e-12] # 3.27369962e-01 4.66323895e-14\n",
    "kpca1 = KernelPCA(n_components=num_modes, kernel=\"rbf\", fit_inverse_transform=True, gamma=x[0], alpha=x[1])\n",
    "kpca1.fit(rho_msub.T)\n",
    "X_pca = kpca1.fit_transform(rho_msub_val.T)\n",
    "X_back = kpca1.inverse_transform(X_pca)\n",
    "X_back = X_back.T\n",
    "error_adv = rho_msub_val-X_back\n",
    "error_norm_adv = linalg.norm(error_adv)\n",
    "print(error_norm_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1114d491-ae37-4775-866a-f478df888467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    number of modes  PCA error  KPCA error\n",
      "0                 2  16.714446   27.560622\n",
      "1                 3  11.601645   11.954918\n",
      "2                 4   9.173239    8.782353\n",
      "3                 5   7.596694    6.668534\n",
      "4                 6   6.108573    4.950681\n",
      "5                 7   4.723315    3.676183\n",
      "6                 8   3.120358    2.441859\n",
      "7                 9   1.551486    1.339403\n",
      "8                10   1.229338    0.549276\n",
      "9                11   1.019850    0.123205\n",
      "10               12   0.848673    0.072738\n",
      "11               13   0.717967    0.043660\n",
      "12               14   0.612778    0.029549\n"
     ]
    }
   ],
   "source": [
    "# kpca_adv = KernelPCA(n_components=num_modes, kernel=\"rbf\", fit_inverse_transform=True, gamma=0.11,\n",
    "#                      alpha=1e-11)  #  1e-11\n",
    "x = [3.27369962e-01, 4.66323895e-12] # 4.66323895e-14\n",
    "# num_modes = 1\n",
    "modes = []\n",
    "PCA_error = []\n",
    "KPCA_error = []\n",
    "\n",
    "for num_modes in range(2,15):\n",
    "    modes.append(num_modes)\n",
    "    kpca_adv = KernelPCA(n_components=num_modes, kernel=\"rbf\", fit_inverse_transform=True, gamma=x[0], alpha=x[1])\n",
    "\n",
    "    # fftout = fftpack.fftn(rho_msub.T)\n",
    "\n",
    "    pca = PCA(n_components=num_modes)\n",
    "\n",
    "    # pca_fft = PCA(n_components=num_modes)\n",
    "    # pca.fit(rho_msub.T)\n",
    "    # X_pca_lin = pca.fit_transform(rho_msub_val.T)\n",
    "    X_pca_lin = pca.fit_transform(rho_msub.T)\n",
    "\n",
    "    # X_pca_lin_fft = pca_fft.fit_transform(fftout.real)\n",
    "\n",
    "    # gram = cosine_kernel(rho_msub.T, rho_msub.T)\n",
    "    # X_pca_man = pcam.fit_transform(gram)\n",
    "    # X_pca = kpca.fit_transform(rho_msub.T)\n",
    "    # explained_variance_kpca = (kpca.eigenvalues_ ** 2) / (len(rho_msub.T) - 1)\n",
    "\n",
    "    # print(np.sum(explained_variance_kpca))\n",
    "\n",
    "    # kpca_test = KernelPCA(n_components=1920, kernel=\"rbf\", fit_inverse_transform=True, gamma=0.11)  #  0.11\n",
    "\n",
    "    # kpca_test.fit(rho_msub.T)\n",
    "    # X_pca_test = kpca_test.fit_transform(rho_msub_val.T)\n",
    "    # X_pca_test = kpca_test.fit_transform(rho_msub.T)\n",
    "    # explained_variance_kpca_test = (kpca_test.eigenvalues_ ** 2) / (len(rho_msub.T) - 1)\n",
    "\n",
    "    # print(np.sum(explained_variance_kpca)/np.sum(explained_variance_kpca_test))\n",
    "\n",
    "    # kpca_adv.fit(rho_msub.T)\n",
    "    # X_pca_adv = kpca_adv.fit_transform(rho_msub_val.T)\n",
    "    X_pca_adv = kpca_adv.fit_transform(rho_msub.T)\n",
    "\n",
    "    X_back_adv = kpca_adv.inverse_transform(X_pca_adv)\n",
    "\n",
    "    X_back_lin = pca.inverse_transform(X_pca_lin)\n",
    "    # X_back_lin_fft = pca_fft.inverse_transform(X_pca_lin_fft)\n",
    "    # X_back_lin_fft_inv = fftpack.ifftn(X_back_lin_fft)\n",
    "\n",
    "    # K = my_kernel(X_pca,X_pca)\n",
    "    # K.flat[:: nPoints + 1] += 1\n",
    "    # dual_coef_ = linalg.solve(K, rho_msub.T, sym_pos=True, overwrite_a=True)\n",
    "    # K = my_kernel(X_pca, X_pca)\n",
    "    # X_back_man_nonl = np.dot(K, dual_coef_).T\n",
    "\n",
    "    X_back_lin = X_back_lin.T\n",
    "\n",
    "    # X_back = X_back.T\n",
    "    X_back_adv = X_back_adv.T\n",
    "\n",
    "    # X_back_lin_fft_inv = X_back_lin_fft_inv.T\n",
    "\n",
    "    # error = rho_msub-X_back\n",
    "    # error_norm = linalg.norm(error)\n",
    "    # print('error_norm_rbf:', error_norm)  # Error in reconstruction using built-in rbf kpca\n",
    "\n",
    "    error_adv = rho_msub-X_back_adv\n",
    "    error_norm_adv = linalg.norm(error_adv)\n",
    "    # print('error_norm_rbf with input alpha:', error_norm_adv)  # Error in reconstruction using built-in rbf kpca\n",
    "    KPCA_error.append(error_norm_adv) \n",
    "\n",
    "\n",
    "    error_lin = rho_msub-X_back_lin\n",
    "    error_norm_lin = linalg.norm(error_lin)  # , ord=inf\n",
    "    # print('error_norm_lin:', error_norm_lin)   # Error in reconstruction using built-in linear pca with\n",
    "    PCA_error.append(error_norm_lin) \n",
    "\n",
    "    # error_lin_fft = fftout.real - X_back_lin_fft.T\n",
    "    # error_lin_fft = rho_msub - X_back_lin_fft_inv\n",
    "    # error_norm_lin_fft = linalg.norm(error_lin_fft)  # , ord=inf\n",
    "    # print('error_norm_lin_fft:', error_norm_lin_fft)  # Error in reconstruction using built-in linear pca with\n",
    "\n",
    "\n",
    "    # fftin_resh = fftout.real.reshape(2000, 20, 24, 4)\n",
    "    # fftout_resh = error_lin_fft.reshape(2000, 20, 24, 4)\n",
    "    # error = rho_msub - X_back_lin_fft_inv\n",
    "    # error = np.reshape(error.T, newshape=(2000, 20, 24, 4))\n",
    "    # Path(\"./output/\").mkdir(parents=True, exist_ok=True)\n",
    "    # plt.figure()\n",
    "    # plt.rcParams.update({'font.size': 14})  # increase the font size\n",
    "    # mpl.rcParams['legend.fontsize'] = 15\n",
    "    # plt.xlabel(\"Longitude [deg]\")\n",
    "    # plt.ylabel(\"Latitude [deg]\")\n",
    "    # plt.contourf(np.rad2deg(phi), np.rad2deg(t), np.absolute(error[10, :19, :, 0])/training_data[10, :19, :, 0]*100,\n",
    "    #              cmap=\"inferno\", levels=900)\n",
    "    # plt.colorbar()\n",
    "    # plt.grid(True)\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig('output/fft_error.png')\n",
    "\n",
    "    # error = rho_msub-X_back_lin\n",
    "    # error = np.reshape(error.T, newshape=(2000, 20, 24, 4))\n",
    "    # plt.figure()\n",
    "    # plt.rcParams.update({'font.size': 14})  # increase the font size\n",
    "    # mpl.rcParams['legend.fontsize'] = 15\n",
    "    # plt.xlabel(\"Longitude [deg]\")\n",
    "    # plt.ylabel(\"Latitude [deg]\")\n",
    "    # plt.contourf(np.rad2deg(phi), np.rad2deg(t), np.absolute(error[10, :19, :, 0])/training_data[10, :19, :, 0]*100,\n",
    "    #              cmap=\"inferno\", levels=900)\n",
    "    # plt.colorbar()\n",
    "    # plt.grid(True)\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig('output/ReconstructionError_pca.png')\n",
    "\n",
    "    # error_adv = rho_msub-X_back_adv\n",
    "    # error_adv = np.reshape(error_adv.T, newshape=(2000, 20, 24, 4))\n",
    "    # plt.figure()\n",
    "    # plt.rcParams.update({'font.size': 14})  # increase the font size\n",
    "    # mpl.rcParams['legend.fontsize'] = 15\n",
    "    # plt.xlabel(\"Longitude [deg]\")\n",
    "    # plt.ylabel(\"Latitude [deg]\")\n",
    "    # plt.contourf(np.rad2deg(phi), np.rad2deg(t), np.absolute(error_adv[10, :19, :, 0])/training_data[10, :19, :, 0]*100,\n",
    "    #              cmap=\"inferno\", levels=900)\n",
    "    # plt.colorbar()\n",
    "    # plt.grid(True)\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig('output/ReconstructionError_kpca_adv.png')\n",
    "\n",
    "    # plt.close('all')\n",
    "\n",
    "data = {'number of modes':modes,'PCA error':PCA_error, 'KPCA error':KPCA_error}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "plt.figure()\n",
    "plt.rcParams.update({'font.size': 14})  # increase the font size\n",
    "mpl.rcParams['legend.fontsize'] = 15\n",
    "plt.xlabel(\"# of modes\")\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.plot(PCA_error, label=\"PCA error\", linewidth=2)\n",
    "plt.plot(KPCA_error, label=\"KPCA error\", linewidth=2)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/PCA_vs_KPCA_error.png')\n",
    "plt.close('all')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ab0d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_modes):\n",
    "    plt.figure()\n",
    "    plt.rcParams.update({'font.size': 14})  # increase the font size\n",
    "    mpl.rcParams['legend.fontsize'] = 15\n",
    "    plt.xlabel(\"Longitude [deg]\")\n",
    "    plt.ylabel(\"Latitude [deg]\")\n",
    "    # plt.contourf(np.rad2deg(phi), np.rad2deg(t), training_data[10, :19, :, 0] * max_rho, cmap=\"viridis\", levels=900)\n",
    "    # X_pca X_pca_adv\n",
    "    plt.plot(X_pca_adv[:, i])\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output/KPCA_mode%d.png'%i)\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "909d0a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 02m 43s]\n",
      "val_loss: 2120.924560546875\n",
      "\n",
      "Best val_loss So Far: 2081.10009765625\n",
      "Total elapsed time: 00h 25m 38s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "        z_size = 10\n",
    "        model = tf.keras.Sequential([\n",
    "                layers.Flatten(),\n",
    "                layers.Dense(20 * 24 * 4, activation='relu'),\n",
    "                layers.Dense(units=hp.Int(\"units\", min_value=450, max_value=650, step=20), activation='relu'),\n",
    "                layers.Dense(units=hp.Int(\"units\", min_value=50, max_value=250, step=20), activation='relu'),\n",
    "                # layers.Dense(64, activation='tanh'),\n",
    "                layers.Dense(32, activation='relu'),\n",
    "                # layers.Dense(16, activation='relu'),\n",
    "                layers.Dense(z_size, activation='relu'),           \n",
    "                layers.Input(shape=(z_size)),\n",
    "                layers.Dense(32, activation='relu'),\n",
    "                layers.Dense(units=hp.Int(\"units\", min_value=50, max_value=250, step=20), activation='relu'),\n",
    "                layers.Dense(units=hp.Int(\"units\", min_value=450, max_value=650, step=20), activation='relu'),\n",
    "                layers.Dense(20 * 24 * 4, activation='relu')\n",
    "        ])\n",
    "        model.compile(\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "# build_model(kt.HyperParameters())\n",
    "tuner = kt.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=20)\n",
    "tuner.search(training_data_resh, training_data_resh, epochs=50, \n",
    "        validation_data=(validation_data_resh, validation_data_resh))\n",
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe11f84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 1920)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1920)              3688320   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 470)               902870    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 470)               221370    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                15072     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      " input_1 (InputLayer)        multiple                  0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                352       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 470)               15510     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 470)               221370    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1920)              904320    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,969,514\n",
      "Trainable params: 5,969,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.build(input_shape=(None, 20 * 24 * 4))\n",
    "best_model.summary()\n",
    "\n",
    "# tuner.results_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44acf78b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data_resh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\My_folder\\Documents\\Politecnico di Milano\\My thesis\\test_auto\\HASDM_ROM\\POD_jupyter.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/My_folder/Documents/Politecnico%20di%20Milano/My%20thesis/test_auto/HASDM_ROM/POD_jupyter.ipynb#ch0000020?line=36'>37</a>\u001b[0m autoencoder \u001b[39m=\u001b[39m Autoencoder(num_modes)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/My_folder/Documents/Politecnico%20di%20Milano/My%20thesis/test_auto/HASDM_ROM/POD_jupyter.ipynb#ch0000020?line=37'>38</a>\u001b[0m autoencoder\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39mlosses\u001b[39m.\u001b[39mMeanSquaredError())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/My_folder/Documents/Politecnico%20di%20Milano/My%20thesis/test_auto/HASDM_ROM/POD_jupyter.ipynb#ch0000020?line=39'>40</a>\u001b[0m history \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39mfit(training_data_resh, training_data_resh,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/My_folder/Documents/Politecnico%20di%20Milano/My%20thesis/test_auto/HASDM_ROM/POD_jupyter.ipynb#ch0000020?line=40'>41</a>\u001b[0m                 batch_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,  \u001b[39m# play with me\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/My_folder/Documents/Politecnico%20di%20Milano/My%20thesis/test_auto/HASDM_ROM/POD_jupyter.ipynb#ch0000020?line=41'>42</a>\u001b[0m                 epochs\u001b[39m=\u001b[39m \u001b[39m50\u001b[39m,  \u001b[39m# 20\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/My_folder/Documents/Politecnico%20di%20Milano/My%20thesis/test_auto/HASDM_ROM/POD_jupyter.ipynb#ch0000020?line=42'>43</a>\u001b[0m                 shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/My_folder/Documents/Politecnico%20di%20Milano/My%20thesis/test_auto/HASDM_ROM/POD_jupyter.ipynb#ch0000020?line=43'>44</a>\u001b[0m                 validation_data\u001b[39m=\u001b[39m(validation_data_resh, validation_data_resh))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/My_folder/Documents/Politecnico%20di%20Milano/My%20thesis/test_auto/HASDM_ROM/POD_jupyter.ipynb#ch0000020?line=45'>46</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(history\u001b[39m.\u001b[39mhistory\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/My_folder/Documents/Politecnico%20di%20Milano/My%20thesis/test_auto/HASDM_ROM/POD_jupyter.ipynb#ch0000020?line=46'>47</a>\u001b[0m autoencoder\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mencoder\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_data_resh' is not defined"
     ]
    }
   ],
   "source": [
    "class Autoencoder(Model):\n",
    "    def __init__(self, z_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.z_size = z_size\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "                layers.Flatten(),\n",
    "                layers.Dense(20 * 24 * 4, activation='relu'),\n",
    "                layers.Dense(512, activation='relu'),\n",
    "                layers.Dense(128, activation='relu'),\n",
    "                # layers.Dense(64, activation='tanh'),\n",
    "                layers.Dense(32, activation='relu'),\n",
    "                # layers.Dense(16, activation='relu'),\n",
    "                layers.Dense(z_size, activation='relu')           \n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "                layers.Input(shape=(z_size)),\n",
    "                layers.Dense(32, activation='relu'),\n",
    "                layers.Dense(128, activation='relu'),\n",
    "                layers.Dense(512, activation='relu'),\n",
    "                layers.Dense(20 * 24 * 4, activation='relu')\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "# print(X_pca.shape)      \n",
    "# print(X_pca_val.shape)\n",
    "# print(training_data_resh.shape)\n",
    "# print(validation_data_resh.shape)\n",
    "# exit()\n",
    "num_modes = 10\n",
    "run = True\n",
    "if run:\n",
    "    autoencoder = Autoencoder(num_modes)\n",
    "    autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "\n",
    "    history = autoencoder.fit(training_data_resh, training_data_resh,\n",
    "                    batch_size=5,  # play with me\n",
    "                    epochs= 50,  # 20\n",
    "                    shuffle=True,\n",
    "                    validation_data=(validation_data_resh, validation_data_resh))\n",
    "\n",
    "    loss = list(history.history.values())\n",
    "    autoencoder.encoder.save('encoder')\n",
    "    autoencoder.decoder.save('decoder')\n",
    "else:\n",
    "    encoder = tf.keras.models.load_model('encoder')\n",
    "    decoder = tf.keras.models.load_model('decoder')\n",
    "\n",
    "\n",
    "encoded = autoencoder.encoder(validation_data_resh).numpy()\n",
    "decoded = autoencoder.decoder(encoded).numpy()\n",
    "np.savetxt('output/atm/encoded.txt', encoded, delimiter=',')\n",
    "np.savetxt('output/atm/training_data.txt', training_data_resh, delimiter=',')\n",
    "np.savetxt('output/atm/validation_data.txt', validation_data_resh, delimiter=',')\n",
    "np.savetxt('output/atm/decoded.txt', decoded, delimiter=',')\n",
    "\n",
    "plt.figure()\n",
    "plt.rcParams.update({'font.size': 14})  # increase the font size\n",
    "mpl.rcParams['legend.fontsize'] = 15\n",
    "plt.xlabel(\"Number of Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(loss[0], label=\"Train\", linewidth=2)\n",
    "plt.plot(loss[1], label=\"Validation\", linewidth=2)\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/loss_atm.png')\n",
    "\n",
    "error = -validation_data_resh + decoded\n",
    "error = np.reshape(error, newshape=(nPoints_val, 20, 24, 4))\n",
    "plt.figure()\n",
    "plt.rcParams.update({'font.size': 14})  # increase the font size\n",
    "mpl.rcParams['legend.fontsize'] = 15\n",
    "plt.xlabel(\"Longitude [deg]\")\n",
    "plt.ylabel(\"Latitude [deg]\")\n",
    "plt.contourf(np.rad2deg(phi), np.rad2deg(t), np.absolute(error[10, :19, :, 0])/validation_data[10, :19, :, 0]*100,\n",
    "                cmap=\"inferno\", levels=900)\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/ReconstructionError_nn.png')\n",
    "error_norm_nn = linalg.norm(decoded - validation_data_resh)  # , ord=inf\n",
    "print('error_norm_nn:', error_norm_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71d4f515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   number of modes  PCA error  KPCA error  Autoencoder erros\n",
      "0                2  16.714446   25.821876            66.8464\n",
      "1                4   9.173239    8.507736            28.1242\n",
      "2                6   6.108573    4.921118            25.1675\n",
      "3                8   3.120358    2.429778            26.8981\n",
      "4               10   1.229338    0.286163            21.2226\n",
      "5               12   0.848673    0.072301            18.3057\n"
     ]
    }
   ],
   "source": [
    "errorae = [66.8464, 28.1242, 25.1675, 26.8981, 21.2226, 18.3057]\n",
    "modes = [2, 4, 6, 8, 10, 12]\n",
    "PCA_error = [16.714446, 9.173239, 6.108573, 3.120358, 1.229338, 0.848673]\n",
    "KPCA_error = [25.821876, 8.507736, 4.921118, 2.429778, 0.286163, 0.072301]\n",
    "datam = {'number of modes':modes,'PCA error':PCA_error, 'KPCA error':KPCA_error, 'Autoencoder erros':errorae}\n",
    "df = pd.DataFrame(datam)\n",
    "print(df)\n",
    "plt.figure()\n",
    "plt.rcParams.update({'font.size': 14})  # increase the font size\n",
    "mpl.rcParams['legend.fontsize'] = 15\n",
    "plt.xlabel(\"Number of modes\")\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.plot(modes, PCA_error, label=\"PCA\", linewidth=2)\n",
    "plt.plot(modes, KPCA_error, label=\"KPCA\", linewidth=2)\n",
    "plt.plot(modes, errorae, label=\"Autoencoder\", linewidth=2)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/error_comparison.png')\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bedb68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, losses\n",
    "# from tensorflow.keras.models import Model\n",
    "# import keras_tuner as kt\n",
    "# import modred as mr\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from scipy import linalg\n",
    "from sklearn.preprocessing import normalize\n",
    "# from scipy import fftpack\n",
    "from pathlib import Path\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "\n",
    "mpl.use('Agg')\n",
    "\n",
    "# density_df_400_2013 = pd.read_csv('Data/2013_HASDM_400-475KM.den', delim_whitespace=True,\n",
    "#                                   header=None)\n",
    "# density_np_400_2013 = pd.DataFrame.to_numpy(density_df_400_2013)\n",
    "# del density_df_400_2013\n",
    "# If you want to add more altitudes (increase the initial dimension of the problem), uncomment the followings:\n",
    "density_df_500_2013 = pd.read_csv('Data/2013_HASDM_500-575KM.den', delim_whitespace=True,\n",
    "                                  header=None)\n",
    "density_np_500_2013 = pd.DataFrame.to_numpy(density_df_500_2013)\n",
    "del density_df_500_2013\n",
    "\n",
    "# If you want to add more data (increase the time instants), uncomment the followings:\n",
    "# density_df_400_2014 = pd.read_csv('Data/2014_HASDM_400-475KM.den', delim_whitespace=True,\n",
    "#                                   header=None)\n",
    "# density_np_400_2014 = pd.DataFrame.to_numpy(density_df_400_2014)\n",
    "# del density_df_400_2014\n",
    "\n",
    "nt = 19\n",
    "nphi = 24\n",
    "\n",
    "t = np.linspace(-np.pi / 2, np.pi / 2, nt)\n",
    "phi = np.linspace(0, np.deg2rad(345), nphi)\n",
    "\n",
    "# max_rho1 = np.max(density_np_400_2013[:, 10])\n",
    "# max_rho2 = np.max(density_np_400_2014[:, 10])\n",
    "# max_rho = np.max(np.array([max_rho1, max_rho2]))\n",
    "# density_np_400_2013[:, 10] = density_np_400_2013[:, 10] / max_rho\n",
    "# density_np_400_2014[:, 10] = density_np_400_2014[:, 10] / max_rho\n",
    "\n",
    "# max_rho = np.max(density_np_400_2013[:, 10])\n",
    "max_rho = np.max(density_np_500_2013[:, 10])\n",
    "# max_rho = np.max(np.array([max_rho2, max_rho]))\n",
    "\n",
    "# density_np_400_2013[:, 10] = density_np_400_2013[:, 10] / max_rho\n",
    "density_np_500_2013[:, 10] = density_np_500_2013[:, 10] / max_rho\n",
    "# density_np_400_2014[:, 10] = density_np_400_2014[:, 10] / max_rho\n",
    "\n",
    "rho_list = []\n",
    "rho_list1 = []\n",
    "rho_list2 = []\n",
    "\n",
    "for i in range(int(1331520 / (nt * nphi))):  # 1335168\n",
    "    # rho_400_i_2013 = density_np_400_2013[i * (4 * nt * nphi):(i + 1) * (4 * nt * nphi), 10]\n",
    "    # rho_polar_400_i_2013 = np.reshape(rho_400_i_2013, (nt, nphi, 4))\n",
    "\n",
    "    # rho_400_i_2014 = density_np_400_2014[i * (4 * nt * nphi):(i + 1) * (4 * nt * nphi), 10]\n",
    "    # rho_polar_400_i_2014 = np.reshape(rho_400_i_2014, (nt, nphi, 4))\n",
    "\n",
    "    rho_500_i = density_np_500_2013[i * (4 * nt * nphi):(i + 1) * (4 * nt * nphi), 10]\n",
    "    rho_polar_500_i_2013 = np.reshape(rho_500_i, (nt, nphi, 4))\n",
    "    #\n",
    "    # rho_polar = np.concatenate(\n",
    "    #     (rho_polar_400_i_2013, rho_polar_400_i_2014), axis=2)\n",
    "\n",
    "    # rho_polar_2013 = rho_polar_400_i_2013\n",
    "    # rho_polar_2013 = np.concatenate(\n",
    "    #     (rho_polar_400_i_2013, rho_polar_500_i_2013), axis=2)\n",
    "\n",
    "    # rho_polar_2014 = rho_polar_400_i_2014\n",
    "\n",
    "    # rho_list1.append(rho_polar_400_i_2013)\n",
    "    # rho_list2.append(rho_polar_400_i_2014)\n",
    "    rho_list1.append(rho_polar_500_i_2013)\n",
    "\n",
    "\n",
    "\n",
    "# rho1 = np.array(rho_list1)\n",
    "# rho2 = np.array(rho_list2)\n",
    "# rho = np.concatenate((rho1, rho2), axis=0)  # Shape: (5840, 19, 24, 4)\n",
    "\n",
    "rho = np.array(rho_list1)\n",
    "\n",
    "rho_zeros = np.zeros((2920, 20, 24, 4))  # 2920, 20, 24, 4 \n",
    "rho_zeros[:, :nt, :nphi, :] = rho\n",
    "del rho_list1, rho  #, rho_list2, rho1, rho2\n",
    "\n",
    "training_data = rho_zeros[:2000] # 2000\n",
    "validation_data = rho_zeros[2000:]\n",
    "\n",
    "training_data_resh = np.reshape(training_data, newshape=(2000, 20*24*4))\n",
    "nPoints_val = len(rho_zeros) - len(training_data)\n",
    "validation_data_resh = np.reshape(validation_data, newshape=(nPoints_val, 20*24*4))\n",
    "\n",
    "\n",
    "nPoints_val = 920  # 840 920\n",
    "validation_data_resh = np.reshape(validation_data, newshape=(nPoints_val, 20*24*4))\n",
    "rhoavg_val = np.mean(validation_data_resh, axis=0)  # Compute mean\n",
    "rho_msub_val = validation_data_resh.T - np.tile(rhoavg_val, (nPoints_val, 1)).T  # Mean-subtracted data\n",
    "\n",
    "# print(training_data_resh.shape)\n",
    "rhoavg = np.mean(training_data_resh, axis=0)  # Compute mean\n",
    "nPoints = 2000 # 2000\n",
    "rho_msub = training_data_resh.T - np.tile(rhoavg, (nPoints, 1)).T  # Mean-subtracted data\n",
    "num_modes = 10\n",
    "\n",
    "# def mykpca(x):\n",
    "#     try: \n",
    "#         kpca = KernelPCA(n_components=10, kernel=\"rbf\", fit_inverse_transform=True, gamma=x[0], alpha=4.66323895e-12)\n",
    "#         X_pca = kpca.fit_transform(rho_msub.T)\n",
    "#         X_back = kpca.inverse_transform(X_pca)\n",
    "#         X_back = X_back.T\n",
    "#         error_adv = rho_msub-X_back\n",
    "#         error_norm_adv = linalg.norm(error_adv)\n",
    "#         return error_norm_adv\n",
    "#     except:\n",
    "#         return 1e+10\n",
    "# gamma_init = np.linspace(0.1,0.6,num=5)\n",
    "# alpha_init = np.linspace(9.52148437e-14, 9.52148437e-9, num=5)\n",
    "# res_x = []\n",
    "# res_value = []\n",
    "# for i in range(1):\n",
    "#     x0 = gamma_init[i] # alpha_init[i]\n",
    "#     # bounds = [(0.2, 0.4), (1e-14, 1e-12)]\n",
    "#     res = minimize(mykpca, x0, method='Nelder-Mead', tol=1e-13, options={'maxiter':10, 'disp': True})\n",
    "#     # res = differential_evolution(mykpca, bounds, maxiter=10, tol=1e-14, disp=True)\n",
    "#     res_x.append(res.x)\n",
    "#     res_value.append(res.fun)\n",
    "# print(res_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc0f4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41124215511636236\n",
      "0.0013024720672199785\n",
      "0.22423398328690808\n",
      "0.04276640939152378\n"
     ]
    }
   ],
   "source": [
    "x = [0.2575, 4.66323895e-12] # 3.27369962e-01 4.66323895e-14\n",
    "kpca1 = KernelPCA(n_components=num_modes, kernel=\"rbf\", fit_inverse_transform=True, gamma=x[0], alpha=x[1])\n",
    "kpca1.fit(rho_msub.T)\n",
    "X_pca = kpca1.fit_transform(rho_msub_val.T)\n",
    "X_back = kpca1.inverse_transform(X_pca)\n",
    "X_back = X_back.T\n",
    "error_adv = rho_msub_val-X_back\n",
    "error_norm_adv = linalg.norm(error_adv)\n",
    "print(error_norm_adv)\n",
    "error_adv = np.reshape(error_adv, newshape=(nPoints_val, 20, 24, 4))\n",
    "X_back = X_back + np.tile(rhoavg_val, (nPoints_val, 1)).T\n",
    "X_back_kpca = np.reshape(X_back, newshape=(nPoints_val, 20, 24, 4))\n",
    "\n",
    "print(np.absolute(error_adv[0, :19, :, 0]).max())\n",
    "print(validation_data[0, :19, :, 0].max())\n",
    "err = np.absolute(error_adv[0, :19, :, 0])/validation_data[0, :19, :, 0]\n",
    "print(err.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81fdff10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008016703025546718\n",
      "0.007385226171594428\n"
     ]
    }
   ],
   "source": [
    "plt.close(\"all\")\n",
    "plt.rcParams.update({'font.size': 14})  # increase the font size\n",
    "mpl.rcParams['legend.fontsize'] = 15\n",
    "plt.xlabel(\"Longitude [deg]\")\n",
    "plt.ylabel(\"Latitude [deg]\")\n",
    "plt.contourf(np.rad2deg(phi), np.rad2deg(t), np.absolute(error_adv[0, :19, :, 0])/validation_data[0, :19, :, 0]*100,\n",
    "                cmap=\"inferno\", levels=900)\n",
    "plt.colorbar(label=\"[%]\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/ReconstructionError_kpca.png')\n",
    "print(np.absolute(error_adv).max())\n",
    "\n",
    "plt.figure() \n",
    "plt.rcParams.update({'font.size': 14})  # increase the font size\n",
    "mpl.rcParams['legend.fontsize'] = 15\n",
    "plt.xlabel(\"Longitude [deg]\")\n",
    "plt.ylabel(\"Latitude [deg]\")\n",
    "plt.contourf(np.rad2deg(phi), np.rad2deg(t), validation_data[0, :19, :, 0]*max_rho,\n",
    "                cmap=\"inferno\", levels=900)\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/dens_input.png')\n",
    "plt.figure() \n",
    "plt.rcParams.update({'font.size': 14})  # increase the font size\n",
    "mpl.rcParams['legend.fontsize'] = 15\n",
    "plt.xlabel(\"Longitude [deg]\")\n",
    "plt.ylabel(\"Latitude [deg]\")\n",
    "plt.contourf(np.rad2deg(phi), np.rad2deg(t), X_back_kpca[0, :19, :, 0]*max_rho,\n",
    "                cmap=\"inferno\", levels=900)\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/recons_kpca.png')\n",
    "\n",
    "pca = PCA(n_components=num_modes)\n",
    "pca.fit(rho_msub.T)\n",
    "X_pca_lin = pca.fit_transform(rho_msub_val.T)\n",
    "X_back_lin = pca.inverse_transform(X_pca_lin)\n",
    "X_back_lin = X_back_lin.T\n",
    "error_lin = rho_msub_val-X_back_lin\n",
    "error_lin = np.reshape(error_lin, newshape=(nPoints_val, 20, 24, 4))\n",
    "\n",
    "error_norm_lin = linalg.norm(error_lin)\n",
    "plt.figure() \n",
    "plt.rcParams.update({'font.size': 14})  # increase the font size\n",
    "mpl.rcParams['legend.fontsize'] = 15\n",
    "plt.xlabel(\"Longitude [deg]\")\n",
    "plt.ylabel(\"Latitude [deg]\")\n",
    "plt.contourf(np.rad2deg(phi), np.rad2deg(t), np.absolute(error_lin[0, :19, :, 0])/validation_data[0, :19, :, 0]*100,\n",
    "                cmap=\"inferno\", levels=900)\n",
    "plt.colorbar(label=\"[%]\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/ReconstructionError_pca.png')\n",
    "print(np.absolute(error_lin).max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc4ddb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11549179757984c6a788bb4b26fdfb87dcdd8918e837694347641bc29ad13874"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
