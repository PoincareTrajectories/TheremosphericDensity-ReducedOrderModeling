{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e19b5b-0d58-4a9e-8f66-d7a97d51ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, losses\n",
    "# from tensorflow.keras.models import Model\n",
    "# import modred as mr\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from scipy import linalg\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy import fftpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0b14395f-b08f-4c68-8e52-445b43900127",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.use('Agg')\n",
    "\n",
    "density_df_400_2013 = pd.read_csv('Data/2013_HASDM_500-575KM.den', delim_whitespace=True,\n",
    "                                  header=None)\n",
    "density_np_400_2013 = pd.DataFrame.to_numpy(density_df_400_2013)\n",
    "del density_df_400_2013\n",
    "\n",
    "# density_df_400_2014 = pd.read_csv('Data/2014_HASDM_400-475KM.den', delim_whitespace=True,\n",
    "#                                   header=None)\n",
    "# density_np_400_2014 = pd.DataFrame.to_numpy(density_df_400_2014)\n",
    "# del density_df_400_2014\n",
    "# density_df_500_2013 = pd.read_csv('Data/2013_HASDM_500-575KM.den', delim_whitespace=True,\n",
    "#                                   header=None)\n",
    "# density_np_500_2013 = pd.DataFrame.to_numpy(density_df_500_2013)\n",
    "# del density_df_500_2013\n",
    "nt = 19\n",
    "nphi = 24\n",
    "\n",
    "t = np.linspace(-np.pi / 2, np.pi / 2, nt)\n",
    "phi = np.linspace(0, np.deg2rad(345), nphi)\n",
    "\n",
    "# max_rho1 = np.max(density_np_400_2013[:, 10])\n",
    "# max_rho2 = np.max(density_np_400_2014[:, 10])\n",
    "# max_rho = np.max(np.array([max_rho1, max_rho2]))\n",
    "# density_np_400_2013[:, 10] = density_np_400_2013[:, 10] / max_rho\n",
    "# density_np_400_2014[:, 10] = density_np_400_2014[:, 10] / max_rho\n",
    "\n",
    "max_rho = np.max(density_np_400_2013[:, 10])\n",
    "density_np_400_2013[:, 10] = density_np_400_2013[:, 10] / max_rho\n",
    "\n",
    "rho_list = []\n",
    "rho_list1 = []\n",
    "rho_list2 = []\n",
    "\n",
    "for i in range(int(1331520 / (nt * nphi))):  # 1335168\n",
    "    rho_400_i_2013 = density_np_400_2013[i * (4 * nt * nphi):(i + 1) * (4 * nt * nphi), 10]\n",
    "    rho_polar_400_i_2013 = np.reshape(rho_400_i_2013, (nt, nphi, 4))\n",
    "\n",
    "    # rho_400_i_2014 = density_np_400_2013[i * (4 * nt * nphi):(i + 1) * (4 * nt * nphi), 10]\n",
    "    # rho_polar_400_i_2014 = np.reshape(rho_400_i_2014, (nt, nphi, 4))\n",
    "\n",
    "    # rho_500_i = density_np_500_2013[i * (4 * nt * nphi):(i + 1) * (4 * nt * nphi), 10]\n",
    "    # rho_polar_500_i = np.reshape(rho_500_i, (nt, nphi, 4))\n",
    "    #\n",
    "    # rho_polar = np.concatenate(\n",
    "    #     (rho_polar_400_i_2013, rho_polar_400_i_2014), axis=2)\n",
    "\n",
    "    rho_polar_2013 = rho_polar_400_i_2013\n",
    "    # rho_polar_2014 = rho_polar_400_i_2014\n",
    "\n",
    "    rho_list1.append(rho_polar_2013)\n",
    "    # rho_list2.append(rho_polar_2014)\n",
    "\n",
    "\n",
    "# rho1 = np.array(rho_list1)\n",
    "# rho2 = np.array(rho_list2)\n",
    "# rho = np.concatenate((rho1, rho2), axis=0)  # Shape: (5840, 19, 24, 4)\n",
    "\n",
    "rho = np.array(rho_list1)\n",
    "\n",
    "rho_zeros = np.zeros((2920, 20, 24, 4))  # 5840, 20, 24, 4\n",
    "rho_zeros[:, :nt, :nphi, :] = rho\n",
    "del rho_list1, rho  #, rho_list2, rho1, rho2\n",
    "\n",
    "training_data = rho_zeros[:2000]\n",
    "validation_data = rho_zeros[2000:]\n",
    "\n",
    "training_data_resh = np.reshape(training_data, newshape=(2000, 20*24*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "81060678-b79e-416a-9310-32d3acd3d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_kernel(x, y):\n",
    "    x_normalized = normalize(x, copy=True)\n",
    "    if x is y:\n",
    "        y_normalized = x_normalized\n",
    "    else:\n",
    "        y_normalized = normalize(y, copy=True)\n",
    "    kernels = np.dot(x_normalized, y_normalized.T)\n",
    "    return kernels\n",
    "\n",
    "\n",
    "def my_kernel(X, Y):\n",
    "    # The best one so far: np.dot(np.sin(X), np.sin(Y).T). It may be better than the linear one if a nonlinear\n",
    "    # pre-image would exist\n",
    "    return np.dot(np.sin(X), np.sin(Y).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c5e1f2cb-8caf-4fbf-b748-edea038441f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nPoints_val = 920  # 840\n",
    "# validation_data_resh = np.reshape(validation_data, newshape=(nPoints_val, 20*24*4))\n",
    "# rhoavg = np.mean(validation_data_resh, axis=0)  # Compute mean\n",
    "# rho_msub_val = validation_data_resh.T - np.tile(rhoavg, (nPoints_val, 1)).T  # Mean-subtracted data\n",
    "\n",
    "# print(training_data_resh.shape)\n",
    "rhoavg = np.mean(training_data_resh, axis=0)  # Compute mean\n",
    "nPoints = 2000\n",
    "rho_msub = training_data_resh.T - np.tile(rhoavg, (nPoints, 1)).T  # Mean-subtracted data\n",
    "num_modes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1114d491-ae37-4775-866a-f478df888467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_norm_rbf: 12.724886233509306\n",
      "error_norm_rbf with input alpha: 0.8572154456350575\n",
      "error_norm_sigmoid: 48.416948290006495\n",
      "error_norm_laplacian: 25.177185056304037\n",
      "error_norm_lin: 1.2293381103564867\n",
      "error_norm_lin_fft: 53.197648851987395\n"
     ]
    }
   ],
   "source": [
    "kpca = KernelPCA(n_components=num_modes, kernel=\"rbf\", fit_inverse_transform=True, gamma=0.11)  #  0.11\n",
    "kpca_adv = KernelPCA(n_components=num_modes, kernel=\"rbf\", fit_inverse_transform=True, gamma=0.11,\n",
    "                     alpha=1e-11)  #  0.11\n",
    "# kpca1 = KernelPCA(n_components=num_modes, kernel=\"poly\", fit_inverse_transform=True, degree=5, gamma=1.4e-4, coef0=1e-5)\n",
    "kpca2 = KernelPCA(n_components=num_modes, kernel=\"sigmoid\", fit_inverse_transform=True, gamma=1.4e-2, coef0=1e-5)\n",
    "kpca4 = KernelPCA(n_components=num_modes, kernel=\"laplacian\", fit_inverse_transform=True, gamma=1e-2)\n",
    "fftout = fftpack.fftn(rho_msub.T)\n",
    "\n",
    "# pcam = KernelPCA(n_components=num_modes, kernel=\"precomputed\")  # , fit_inverse_transform=True, gamma=10\n",
    "pca = PCA(n_components=num_modes)\n",
    "pca_fft = PCA(n_components=num_modes)\n",
    "\n",
    "X_pca_lin = pca.fit_transform(rho_msub.T)\n",
    "X_pca_lin_fft = pca_fft.fit_transform(fftout.real)\n",
    "\n",
    "# gram = cosine_kernel(rho_msub.T, rho_msub.T)\n",
    "# X_pca_man = pcam.fit_transform(gram)\n",
    "\n",
    "X_pca = kpca.fit_transform(rho_msub.T)\n",
    "X_pca_adv = kpca_adv.fit_transform(rho_msub.T)\n",
    "# X_pca1 = kpca1.fit_transform(rho_msub.T)\n",
    "X_pca2 = kpca2.fit_transform(rho_msub.T)\n",
    "X_pca4 = kpca4.fit_transform(rho_msub.T)\n",
    "\n",
    "X_back = kpca.inverse_transform(X_pca)\n",
    "X_back_adv = kpca_adv.inverse_transform(X_pca_adv)\n",
    "# X_back1 = kpca1.inverse_transform(X_pca1)\n",
    "X_back2 = kpca2.inverse_transform(X_pca2)\n",
    "X_back4 = kpca4.inverse_transform(X_pca4)\n",
    "\n",
    "\n",
    "X_back_lin = pca.inverse_transform(X_pca_lin)\n",
    "X_back_lin_fft = pca_fft.inverse_transform(X_pca_lin_fft)\n",
    "X_back_lin_fft_inv = fftpack.ifftn(X_back_lin_fft)\n",
    "\n",
    "# K = my_kernel(X_pca,X_pca)\n",
    "# K.flat[:: nPoints + 1] += 1\n",
    "# dual_coef_ = linalg.solve(K, rho_msub.T, sym_pos=True, overwrite_a=True)\n",
    "# K = my_kernel(X_pca, X_pca)\n",
    "# X_back_man_nonl = np.dot(K, dual_coef_).T\n",
    "\n",
    "X_back_lin = X_back_lin.T\n",
    "# X_back1 = X_back1.T\n",
    "# X_back_man = X_back_man.T\n",
    "X_back = X_back.T\n",
    "X_back_adv = X_back_adv.T\n",
    "# X_back1 = X_back1.T\n",
    "X_back2 = X_back2.T\n",
    "X_back4 = X_back4.T\n",
    "X_back_lin_fft_inv = X_back_lin_fft_inv.T\n",
    "\n",
    "error = rho_msub-X_back\n",
    "error_norm = linalg.norm(error)\n",
    "print('error_norm_rbf:', error_norm)  # Error in reconstruction using built-in rbf kpca\n",
    "error_adv = rho_msub-X_back_adv\n",
    "error_norm_adv = linalg.norm(error_adv)\n",
    "print('error_norm_rbf with input alpha:', error_norm_adv)  # Error in reconstruction using built-in rbf kpca\n",
    "\n",
    "# error1 = rho_msub-X_back1\n",
    "# error_norm1 = linalg.norm(error1)\n",
    "# print('error_norm_poly:', error_norm1)\n",
    "\n",
    "error2 = rho_msub-X_back2\n",
    "error_norm2 = linalg.norm(error2)\n",
    "print('error_norm_sigmoid:', error_norm2)\n",
    "\n",
    "error4 = rho_msub-X_back4\n",
    "error_norm4 = linalg.norm(error4)\n",
    "print('error_norm_laplacian:', error_norm4)\n",
    "\n",
    "# error1 = rho_msub-X_back1\n",
    "# error1_norm = linalg.norm(error1)\n",
    "# print('error1_norm:', error1_norm)  # Error in reconstruction using built-in cosine kpca with\n",
    "# a linear pre-image learning\n",
    "# error_man = rho_msub-X_back_man\n",
    "# error_norm_man = linalg.norm(error_man)\n",
    "# print('error_norm_man:', error_norm_man)  # Error in reconstruction using precomputed cosine kpca with\n",
    "# a linear pre-image learning\n",
    "error_lin = rho_msub-X_back_lin\n",
    "error_norm_lin = linalg.norm(error_lin)  # , ord=inf\n",
    "print('error_norm_lin:', error_norm_lin)   # Error in reconstruction using built-in linear pca with\n",
    "# error_lin_fft = fftout.real - X_back_lin_fft.T\n",
    "error_lin_fft = rho_msub - X_back_lin_fft_inv\n",
    "error_norm_lin_fft = linalg.norm(error_lin_fft)  # , ord=inf\n",
    "print('error_norm_lin_fft:', error_norm_lin_fft)  # Error in reconstruction using built-in linear pca with\n",
    "# error_nonl = rho_msub - X_back_man_nonl\n",
    "# error_norm_nonl = linalg.norm(error_nonl)\n",
    "# print('error_norm_nonl:', error_norm_nonl)  # Error in reconstruction using precomputed cosine kpca with\n",
    "# a nonlinear pre-image learning\n",
    "# exit()\n",
    "\n",
    "\n",
    "# fftin_resh = fftout.real.reshape(2000, 20, 24, 4)\n",
    "# fftout_resh = error_lin_fft.reshape(2000, 20, 24, 4)\n",
    "error = rho_msub - X_back_lin_fft_inv\n",
    "error = np.reshape(error.T, newshape=(2000, 20, 24, 4))\n",
    "plt.figure()\n",
    "plt.rcParams.update({'font.size': 14})  # increase the font size\n",
    "mpl.rcParams['legend.fontsize'] = 15\n",
    "plt.xlabel(\"Longitude [deg]\")\n",
    "plt.ylabel(\"Latitude [deg]\")\n",
    "plt.contourf(np.rad2deg(phi), np.rad2deg(t), np.absolute(error[10, :19, :, 0])/training_data[10, :19, :, 0]*100,\n",
    "             cmap=\"inferno\", levels=900)\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('fft_error.png')\n",
    "\n",
    "error = rho_msub-X_back_lin\n",
    "error = np.reshape(error.T, newshape=(2000, 20, 24, 4))\n",
    "plt.figure()\n",
    "plt.rcParams.update({'font.size': 14})  # increase the font size\n",
    "mpl.rcParams['legend.fontsize'] = 15\n",
    "plt.xlabel(\"Longitude [deg]\")\n",
    "plt.ylabel(\"Latitude [deg]\")\n",
    "plt.contourf(np.rad2deg(phi), np.rad2deg(t), np.absolute(error[10, :19, :, 0])/training_data[10, :19, :, 0]*100,\n",
    "             cmap=\"inferno\", levels=900)\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('ReconstructionError_pca.png')\n",
    "\n",
    "error = rho_msub-X_back\n",
    "error = np.reshape(error.T, newshape=(2000, 20, 24, 4))\n",
    "plt.figure()\n",
    "plt.rcParams.update({'font.size': 14})  # increase the font size\n",
    "mpl.rcParams['legend.fontsize'] = 15\n",
    "plt.xlabel(\"Longitude [deg]\")\n",
    "plt.ylabel(\"Latitude [deg]\")\n",
    "plt.contourf(np.rad2deg(phi), np.rad2deg(t), np.absolute(error[10, :19, :, 0])/training_data[10, :19, :, 0]*100,\n",
    "             cmap=\"inferno\", levels=900)\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('ReconstructionError_kpca.png')\n",
    "\n",
    "error_adv = rho_msub-X_back_adv\n",
    "error_adv = np.reshape(error_adv.T, newshape=(2000, 20, 24, 4))\n",
    "plt.figure()\n",
    "plt.rcParams.update({'font.size': 14})  # increase the font size\n",
    "mpl.rcParams['legend.fontsize'] = 15\n",
    "plt.xlabel(\"Longitude [deg]\")\n",
    "plt.ylabel(\"Latitude [deg]\")\n",
    "plt.contourf(np.rad2deg(phi), np.rad2deg(t), np.absolute(error_adv[10, :19, :, 0])/training_data[10, :19, :, 0]*100,\n",
    "             cmap=\"inferno\", levels=900)\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('ReconstructionError_kpca_adv.png')\n",
    "\n",
    "# error = rho_msub-X_back_man_nonl\n",
    "# error = np.reshape(error.T, newshape=(2000, 20, 24, 4))\n",
    "# plt.figure()\n",
    "# plt.rcParams.update({'font.size': 14})  # increase the font size\n",
    "# mpl.rcParams['legend.fontsize'] = 15\n",
    "# plt.xlabel(\"Longitude [deg]\")\n",
    "# plt.ylabel(\"Latitude [deg]\")\n",
    "# plt.contourf(np.rad2deg(phi), np.rad2deg(t), np.absolute(error[10, :19, :, 0])/training_data[10, :19, :, 0]*100,\n",
    "#              cmap=\"inferno\", levels=900)\n",
    "# plt.colorbar()\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('ReconstructionError_kpca_man.png')\n",
    "plt.close('all')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86551f02-7e53-41bb-b3a0-143ad5abedd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a28142-23e8-4fbd-83a6-59ff9876b2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
